{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Gutenberg is a large electronic collection of over 54,000 public domain books. We will be working with a dataset of 3036 books, available to download from [Shibamouli Lahiri](https://web.eecs.umich.edu/~lahiri/gutenberg_dataset.html). This notebook is to prepare the data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filenames = [name for name in os.listdir('txt') if name.endswith('.txt')]\n",
    "authorlist = []\n",
    "for name in filenames:\n",
    "    a, _ = name.split('___')\n",
    "    authorlist.append(a)\n",
    "    with open('txt/'+name, 'r+', encoding='iso-8859-1') as f:\n",
    "        for i in range(4):\n",
    "            f.readline()\n",
    "        data = f.readlines()\n",
    "        f.seek(0)\n",
    "        f.writelines(data)\n",
    "        f.truncate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abraham Lincoln</td>\n",
       "      <td>Abraham Lincoln___Lincoln Letters.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abraham Lincoln</td>\n",
       "      <td>Abraham Lincoln___Lincoln's First Inaugural Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abraham Lincoln</td>\n",
       "      <td>Abraham Lincoln___Lincoln's Gettysburg Address...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abraham Lincoln</td>\n",
       "      <td>Abraham Lincoln___Lincoln's Inaugurals, Addres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abraham Lincoln</td>\n",
       "      <td>Abraham Lincoln___Lincoln's Second Inaugural A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Author                                               Name\n",
       "0  Abraham Lincoln              Abraham Lincoln___Lincoln Letters.txt\n",
       "1  Abraham Lincoln  Abraham Lincoln___Lincoln's First Inaugural Ad...\n",
       "2  Abraham Lincoln  Abraham Lincoln___Lincoln's Gettysburg Address...\n",
       "3  Abraham Lincoln  Abraham Lincoln___Lincoln's Inaugurals, Addres...\n",
       "4  Abraham Lincoln  Abraham Lincoln___Lincoln's Second Inaugural A..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = [name for name in os.listdir('txt') if name.endswith('.txt')]\n",
    "authorlist = []\n",
    "for name in filenames:\n",
    "    a, _ = name.split('___')\n",
    "    authorlist.append(a)\n",
    "titledf = pd.DataFrame({'Author':authorlist, 'Name':filenames})       \n",
    "titledf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to remove the author's name from the text of each file as I believe it may bias the classifier later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in titledf.iterrows():\n",
    "    name = row['Name']\n",
    "    author = row['Author']\n",
    "    with open('txt/'+name, 'r+', encoding='iso-8859-1') as f:\n",
    "        text=f.read()\n",
    "        author_caseless = re.compile(author, re.IGNORECASE)\n",
    "        text = re.sub(author_caseless, '', text)\n",
    "        f.seek(0)\n",
    "        f.writelines(text)\n",
    "        f.truncate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for the classifier to have predictive power, there needs to be sufficient data for each class. We will only use the data with at least 10 texts for each author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2798</td>\n",
       "      <td>2798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>83</td>\n",
       "      <td>2798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>William Wymark Jacobs</td>\n",
       "      <td>Grant Allen___The Great Taboo.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Author                               Name\n",
       "count                    2798                               2798\n",
       "unique                     83                               2798\n",
       "top     William Wymark Jacobs  Grant Allen___The Great Taboo.txt\n",
       "freq                       97                                  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titledf = titledf[list(titledf.Author.value_counts()[author]>=10 for author in titledf.Author)]\n",
    "titledf.to_csv('author_title.csv')\n",
    "titledf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now want to vectorize the texts and save both the tokens and the vocabulary to disk to be used when we analyze the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_names.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(input='filename', min_df=3, max_df=.95, encoding='iso-8859-1')\n",
    "tokens = vectorizer.fit_transform(['txt/'+fname for fname in titledf.Name])\n",
    "joblib.dump(tokens, 'features.pkl')\n",
    "joblib.dump(vectorizer.get_feature_names(), 'feature_names.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
