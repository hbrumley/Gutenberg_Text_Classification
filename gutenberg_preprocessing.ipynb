{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Gutenberg is a large electronic collection of over 54,000 public domain books. We will be working with a dataset of 3036 books, available to download from [Shibamouli Lahiri](https://web.eecs.umich.edu/~lahiri/gutenberg_dataset.html). This notebook is to prepare the data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filenames = [name for name in os.listdir('txt') if name.endswith('.txt')]\n",
    "authorlist = []\n",
    "for name in filenames:\n",
    "    a, _ = name.split('___')\n",
    "    authorlist.append(a)\n",
    "    with open('txt/'+name, 'r+', encoding='iso-8859-1') as f:\n",
    "        for i in range(4):\n",
    "            f.readline()\n",
    "        data = f.readlines()\n",
    "        f.seek(0)\n",
    "        f.writelines(data)\n",
    "        f.truncate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abraham Lincoln</td>\n",
       "      <td>Abraham Lincoln___Lincoln Letters.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abraham Lincoln</td>\n",
       "      <td>Abraham Lincoln___Lincoln's First Inaugural Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abraham Lincoln</td>\n",
       "      <td>Abraham Lincoln___Lincoln's Gettysburg Address...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abraham Lincoln</td>\n",
       "      <td>Abraham Lincoln___Lincoln's Inaugurals, Addres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abraham Lincoln</td>\n",
       "      <td>Abraham Lincoln___Lincoln's Second Inaugural A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Author                                               Name\n",
       "0  Abraham Lincoln              Abraham Lincoln___Lincoln Letters.txt\n",
       "1  Abraham Lincoln  Abraham Lincoln___Lincoln's First Inaugural Ad...\n",
       "2  Abraham Lincoln  Abraham Lincoln___Lincoln's Gettysburg Address...\n",
       "3  Abraham Lincoln  Abraham Lincoln___Lincoln's Inaugurals, Addres...\n",
       "4  Abraham Lincoln  Abraham Lincoln___Lincoln's Second Inaugural A..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = [name for name in os.listdir('txt') if name.endswith('.txt')]\n",
    "authorlist = []\n",
    "for name in filenames:\n",
    "    a, _ = name.split('___')\n",
    "    authorlist.append(a)\n",
    "titledf = pd.DataFrame({'Author':authorlist, 'Name':filenames})       \n",
    "titledf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to remove the author's name from the text of each file as I believe it may bias the classifier later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index, row in titledf.iterrows():\n",
    "    name = row['Name']\n",
    "    author = row['Author']\n",
    "    with open('txt/'+name, 'r+', encoding='iso-8859-1') as f:\n",
    "        text=f.read()\n",
    "        author_caseless = re.compile(author, re.IGNORECASE)\n",
    "        text = re.sub(author_caseless, '', text)\n",
    "        f.seek(0)\n",
    "        f.writelines(text)\n",
    "        f.truncate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now want to vectorize the texts and save both the tokens and the vocabulary to disk to be used when we analyze the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index, row in titledf.iterrows():\n",
    "    name = row['Name']\n",
    "    author = row['Author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(input='filename', min_df=3, max_df=.95, encoding='iso-8859-1')\n",
    "tokens = vectorizer.fit_transform(['txt/'+fname for fname in filenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_names.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(titledf, 'author_title.pkl')\n",
    "joblib.dump(tokens, 'features.pkl')\n",
    "joblib.dump(vectorizer.get_feature_names(), 'feature_names.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
